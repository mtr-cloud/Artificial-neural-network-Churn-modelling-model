{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Grouping data into matrix of features X and output variable y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,3:13]\n",
    "y=df.iloc[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0             1               1        101348.88  \n",
       "1             0               1        112542.58  \n",
       "2             1               0        113931.57  \n",
       "3             0               0         93826.63  \n",
       "4             1               1         79084.10  \n",
       "...         ...             ...              ...  \n",
       "9995          1               0         96270.64  \n",
       "9996          1               1        101699.77  \n",
       "9997          0               1         42085.58  \n",
       "9998          1               0         92888.52  \n",
       "9999          1               0         38190.78  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9995    0\n",
       "9996    0\n",
       "9997    1\n",
       "9998    1\n",
       "9999    0\n",
       "Name: Exited, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "geography=pd.get_dummies(X['Geography'],drop_first=True)\n",
    "gender=pd.get_dummies(X['Gender'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.concat([X,geography,gender],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop Unnecessary columns\n",
    "X=X.drop(['Geography','Gender'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 - Now let's make the ANN!\n",
    "\n",
    "# Importing the Keras libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16958176, -0.46460796,  0.00666099, ..., -0.5698444 ,\n",
       "         1.74309049, -1.09168714],\n",
       "       [-2.30455945,  0.30102557, -1.37744033, ...,  1.75486502,\n",
       "        -0.57369368,  0.91601335],\n",
       "       [-1.19119591, -0.94312892, -1.031415  , ..., -0.5698444 ,\n",
       "        -0.57369368, -1.09168714],\n",
       "       ...,\n",
       "       [ 0.9015152 , -0.36890377,  0.00666099, ..., -0.5698444 ,\n",
       "        -0.57369368,  0.91601335],\n",
       "       [-0.62420521, -0.08179119,  1.39076231, ..., -0.5698444 ,\n",
       "         1.74309049, -1.09168714],\n",
       "       [-0.28401079,  0.87525072, -1.37744033, ...,  1.75486502,\n",
       "        -0.57369368, -1.09168714]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.55204276, -0.36890377,  1.04473698, ...,  1.75486502,\n",
       "        -0.57369368, -1.09168714],\n",
       "       [-1.31490297,  0.10961719, -1.031415  , ..., -0.5698444 ,\n",
       "        -0.57369368, -1.09168714],\n",
       "       [ 0.57162971,  0.30102557,  1.04473698, ..., -0.5698444 ,\n",
       "         1.74309049, -1.09168714],\n",
       "       ...,\n",
       "       [-0.74791227, -0.27319958, -1.37744033, ..., -0.5698444 ,\n",
       "         1.74309049,  0.91601335],\n",
       "       [-0.00566991, -0.46460796, -0.33936434, ...,  1.75486502,\n",
       "        -0.57369368,  0.91601335],\n",
       "       [-0.79945688, -0.84742473,  1.04473698, ...,  1.75486502,\n",
       "        -0.57369368,  0.91601335]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7389    0\n",
       "9275    0\n",
       "2995    0\n",
       "5316    0\n",
       "356     0\n",
       "       ..\n",
       "9225    0\n",
       "4859    0\n",
       "3264    0\n",
       "9845    0\n",
       "2732    1\n",
       "Name: Exited, Length: 8000, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9394    0\n",
       "898     1\n",
       "2398    0\n",
       "5906    0\n",
       "2343    0\n",
       "       ..\n",
       "1037    0\n",
       "2899    0\n",
       "9549    0\n",
       "2740    0\n",
       "6690    0\n",
       "Name: Exited, Length: 2000, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform',activation='relu',input_dim = 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'Adamax', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.6293 - accuracy: 0.7319 - val_loss: 0.5713 - val_accuracy: 0.7933\n",
      "Epoch 2/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.7960 - val_loss: 0.5263 - val_accuracy: 0.7955\n",
      "Epoch 3/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5094 - accuracy: 0.7962 - val_loss: 0.5019 - val_accuracy: 0.7955\n",
      "Epoch 4/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4899 - accuracy: 0.7962 - val_loss: 0.4867 - val_accuracy: 0.7955\n",
      "Epoch 5/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4760 - accuracy: 0.7962 - val_loss: 0.4760 - val_accuracy: 0.7955\n",
      "Epoch 6/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4660 - accuracy: 0.7962 - val_loss: 0.4678 - val_accuracy: 0.7955\n",
      "Epoch 7/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4587 - accuracy: 0.7962 - val_loss: 0.4622 - val_accuracy: 0.7955\n",
      "Epoch 8/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4532 - accuracy: 0.7962 - val_loss: 0.4577 - val_accuracy: 0.7955\n",
      "Epoch 9/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4487 - accuracy: 0.7962 - val_loss: 0.4542 - val_accuracy: 0.7955\n",
      "Epoch 10/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4449 - accuracy: 0.7962 - val_loss: 0.4508 - val_accuracy: 0.7955\n",
      "Epoch 11/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4419 - accuracy: 0.7962 - val_loss: 0.4484 - val_accuracy: 0.7955\n",
      "Epoch 12/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4392 - accuracy: 0.7962 - val_loss: 0.4463 - val_accuracy: 0.7955\n",
      "Epoch 13/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4371 - accuracy: 0.7962 - val_loss: 0.4447 - val_accuracy: 0.7955\n",
      "Epoch 14/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4351 - accuracy: 0.7962 - val_loss: 0.4431 - val_accuracy: 0.7955\n",
      "Epoch 15/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4335 - accuracy: 0.7960 - val_loss: 0.4419 - val_accuracy: 0.7955\n",
      "Epoch 16/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4321 - accuracy: 0.7962 - val_loss: 0.4409 - val_accuracy: 0.7955\n",
      "Epoch 17/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4307 - accuracy: 0.7964 - val_loss: 0.4397 - val_accuracy: 0.7952\n",
      "Epoch 18/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4295 - accuracy: 0.7968 - val_loss: 0.4388 - val_accuracy: 0.7970\n",
      "Epoch 19/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4283 - accuracy: 0.7979 - val_loss: 0.4379 - val_accuracy: 0.7993\n",
      "Epoch 20/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4273 - accuracy: 0.7992 - val_loss: 0.4372 - val_accuracy: 0.8031\n",
      "Epoch 21/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4264 - accuracy: 0.8028 - val_loss: 0.4366 - val_accuracy: 0.8054\n",
      "Epoch 22/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4255 - accuracy: 0.8043 - val_loss: 0.4362 - val_accuracy: 0.8039\n",
      "Epoch 23/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4250 - accuracy: 0.8076 - val_loss: 0.4354 - val_accuracy: 0.8042\n",
      "Epoch 24/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4241 - accuracy: 0.8080 - val_loss: 0.4348 - val_accuracy: 0.8050\n",
      "Epoch 25/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4234 - accuracy: 0.8095 - val_loss: 0.4342 - val_accuracy: 0.8069\n",
      "Epoch 26/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4228 - accuracy: 0.8106 - val_loss: 0.4337 - val_accuracy: 0.8076\n",
      "Epoch 27/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4222 - accuracy: 0.8127 - val_loss: 0.4332 - val_accuracy: 0.8065\n",
      "Epoch 28/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4216 - accuracy: 0.8119 - val_loss: 0.4326 - val_accuracy: 0.8061\n",
      "Epoch 29/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4210 - accuracy: 0.8149 - val_loss: 0.4322 - val_accuracy: 0.8061\n",
      "Epoch 30/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4204 - accuracy: 0.8151 - val_loss: 0.4317 - val_accuracy: 0.8069\n",
      "Epoch 31/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4198 - accuracy: 0.8168 - val_loss: 0.4312 - val_accuracy: 0.8076\n",
      "Epoch 32/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4192 - accuracy: 0.8155 - val_loss: 0.4308 - val_accuracy: 0.8076\n",
      "Epoch 33/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4187 - accuracy: 0.8166 - val_loss: 0.4304 - val_accuracy: 0.8073\n",
      "Epoch 34/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4182 - accuracy: 0.8160 - val_loss: 0.4300 - val_accuracy: 0.8058\n",
      "Epoch 35/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4176 - accuracy: 0.8173 - val_loss: 0.4297 - val_accuracy: 0.8080\n",
      "Epoch 36/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4171 - accuracy: 0.8179 - val_loss: 0.4293 - val_accuracy: 0.8065\n",
      "Epoch 37/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4167 - accuracy: 0.8182 - val_loss: 0.4290 - val_accuracy: 0.8080\n",
      "Epoch 38/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4162 - accuracy: 0.8188 - val_loss: 0.4287 - val_accuracy: 0.8092\n",
      "Epoch 39/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4158 - accuracy: 0.8179 - val_loss: 0.4283 - val_accuracy: 0.8088\n",
      "Epoch 40/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4153 - accuracy: 0.8209 - val_loss: 0.4281 - val_accuracy: 0.8095\n",
      "Epoch 41/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4148 - accuracy: 0.8192 - val_loss: 0.4278 - val_accuracy: 0.8073\n",
      "Epoch 42/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4145 - accuracy: 0.8199 - val_loss: 0.4274 - val_accuracy: 0.8084\n",
      "Epoch 43/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4140 - accuracy: 0.8224 - val_loss: 0.4272 - val_accuracy: 0.8107\n",
      "Epoch 44/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4136 - accuracy: 0.8216 - val_loss: 0.4269 - val_accuracy: 0.8099\n",
      "Epoch 45/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4131 - accuracy: 0.8231 - val_loss: 0.4266 - val_accuracy: 0.8088\n",
      "Epoch 46/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4126 - accuracy: 0.8237 - val_loss: 0.4264 - val_accuracy: 0.8095\n",
      "Epoch 47/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4122 - accuracy: 0.8235 - val_loss: 0.4260 - val_accuracy: 0.8092\n",
      "Epoch 48/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4119 - accuracy: 0.8237 - val_loss: 0.4259 - val_accuracy: 0.8092\n",
      "Epoch 49/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4115 - accuracy: 0.8242 - val_loss: 0.4257 - val_accuracy: 0.8092\n",
      "Epoch 50/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4111 - accuracy: 0.8244 - val_loss: 0.4255 - val_accuracy: 0.8092\n",
      "Epoch 51/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4106 - accuracy: 0.8240 - val_loss: 0.4252 - val_accuracy: 0.8095\n",
      "Epoch 52/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4102 - accuracy: 0.8248 - val_loss: 0.4251 - val_accuracy: 0.8099\n",
      "Epoch 53/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4099 - accuracy: 0.8250 - val_loss: 0.4249 - val_accuracy: 0.8103\n",
      "Epoch 54/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4094 - accuracy: 0.8252 - val_loss: 0.4248 - val_accuracy: 0.8114\n",
      "Epoch 55/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4090 - accuracy: 0.8272 - val_loss: 0.4246 - val_accuracy: 0.8122\n",
      "Epoch 56/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4087 - accuracy: 0.8255 - val_loss: 0.4244 - val_accuracy: 0.8118\n",
      "Epoch 57/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4082 - accuracy: 0.8257 - val_loss: 0.4243 - val_accuracy: 0.8122\n",
      "Epoch 58/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4079 - accuracy: 0.8263 - val_loss: 0.4241 - val_accuracy: 0.8129\n",
      "Epoch 59/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4075 - accuracy: 0.8276 - val_loss: 0.4238 - val_accuracy: 0.8141\n",
      "Epoch 60/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4072 - accuracy: 0.8261 - val_loss: 0.4236 - val_accuracy: 0.8145\n",
      "Epoch 61/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4067 - accuracy: 0.8278 - val_loss: 0.4234 - val_accuracy: 0.8133\n",
      "Epoch 62/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4065 - accuracy: 0.8283 - val_loss: 0.4232 - val_accuracy: 0.8160\n",
      "Epoch 63/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4061 - accuracy: 0.8272 - val_loss: 0.4231 - val_accuracy: 0.8141\n",
      "Epoch 64/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4058 - accuracy: 0.8283 - val_loss: 0.4229 - val_accuracy: 0.8137\n",
      "Epoch 65/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4057 - accuracy: 0.8276 - val_loss: 0.4227 - val_accuracy: 0.8145\n",
      "Epoch 66/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4053 - accuracy: 0.8274 - val_loss: 0.4225 - val_accuracy: 0.8145\n",
      "Epoch 67/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.4052 - accuracy: 0.8296 - val_loss: 0.4223 - val_accuracy: 0.8148\n",
      "Epoch 68/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4046 - accuracy: 0.8287 - val_loss: 0.4225 - val_accuracy: 0.8179\n",
      "Epoch 69/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4047 - accuracy: 0.8296 - val_loss: 0.4221 - val_accuracy: 0.8160\n",
      "Epoch 70/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4044 - accuracy: 0.8298 - val_loss: 0.4220 - val_accuracy: 0.8160\n",
      "Epoch 71/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4041 - accuracy: 0.8302 - val_loss: 0.4218 - val_accuracy: 0.8160\n",
      "Epoch 72/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4038 - accuracy: 0.8298 - val_loss: 0.4218 - val_accuracy: 0.8179\n",
      "Epoch 73/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4035 - accuracy: 0.8300 - val_loss: 0.4217 - val_accuracy: 0.8186\n",
      "Epoch 74/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4034 - accuracy: 0.8296 - val_loss: 0.4215 - val_accuracy: 0.8164\n",
      "Epoch 75/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4031 - accuracy: 0.8306 - val_loss: 0.4214 - val_accuracy: 0.8183\n",
      "Epoch 76/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4029 - accuracy: 0.8308 - val_loss: 0.4212 - val_accuracy: 0.8179\n",
      "Epoch 77/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4027 - accuracy: 0.8308 - val_loss: 0.4211 - val_accuracy: 0.8179\n",
      "Epoch 78/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4024 - accuracy: 0.8313 - val_loss: 0.4210 - val_accuracy: 0.8179\n",
      "Epoch 79/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4021 - accuracy: 0.8309 - val_loss: 0.4210 - val_accuracy: 0.8179\n",
      "Epoch 80/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4022 - accuracy: 0.8309 - val_loss: 0.4208 - val_accuracy: 0.8179\n",
      "Epoch 81/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4018 - accuracy: 0.8313 - val_loss: 0.4208 - val_accuracy: 0.8175\n",
      "Epoch 82/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4017 - accuracy: 0.8313 - val_loss: 0.4207 - val_accuracy: 0.8175\n",
      "Epoch 83/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4014 - accuracy: 0.8306 - val_loss: 0.4207 - val_accuracy: 0.8171\n",
      "Epoch 84/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4012 - accuracy: 0.8311 - val_loss: 0.4206 - val_accuracy: 0.8175\n",
      "Epoch 85/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4011 - accuracy: 0.8311 - val_loss: 0.4205 - val_accuracy: 0.8205\n",
      "Epoch 86/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4009 - accuracy: 0.8308 - val_loss: 0.4204 - val_accuracy: 0.8209\n",
      "Epoch 87/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4008 - accuracy: 0.8309 - val_loss: 0.4203 - val_accuracy: 0.8205\n",
      "Epoch 88/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4007 - accuracy: 0.8313 - val_loss: 0.4203 - val_accuracy: 0.8198\n",
      "Epoch 89/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.8317 - val_loss: 0.4201 - val_accuracy: 0.8209\n",
      "Epoch 90/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4004 - accuracy: 0.8311 - val_loss: 0.4201 - val_accuracy: 0.8213\n",
      "Epoch 91/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4003 - accuracy: 0.8313 - val_loss: 0.4201 - val_accuracy: 0.8205\n",
      "Epoch 92/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4002 - accuracy: 0.8319 - val_loss: 0.4201 - val_accuracy: 0.8198\n",
      "Epoch 93/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4001 - accuracy: 0.8311 - val_loss: 0.4198 - val_accuracy: 0.8205\n",
      "Epoch 94/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3999 - accuracy: 0.8315 - val_loss: 0.4198 - val_accuracy: 0.8205\n",
      "Epoch 95/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3998 - accuracy: 0.8311 - val_loss: 0.4197 - val_accuracy: 0.8217\n",
      "Epoch 96/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3997 - accuracy: 0.8308 - val_loss: 0.4194 - val_accuracy: 0.8232\n",
      "Epoch 97/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3996 - accuracy: 0.8319 - val_loss: 0.4193 - val_accuracy: 0.8224\n",
      "Epoch 98/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3993 - accuracy: 0.8302 - val_loss: 0.4192 - val_accuracy: 0.8220\n",
      "Epoch 99/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3992 - accuracy: 0.8326 - val_loss: 0.4190 - val_accuracy: 0.8217\n",
      "Epoch 100/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3992 - accuracy: 0.8321 - val_loss: 0.4189 - val_accuracy: 0.8213\n"
     ]
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train, y_train,validation_split=0.33, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 6)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "# list all data in history\n",
    "\n",
    "print(model_history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(model_history.history['loss'])\n",
    "plt.plot(model_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.841"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1538,   57],\n",
       "       [ 261,  144]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform',activation='relu',input_dim = 11))\n",
    "classifier.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'he_uniform',activation='relu'))\n",
    "classifier.add(Dropout(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'Adamax', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.6410 - accuracy: 0.7298 - val_loss: 0.5559 - val_accuracy: 0.7925\n",
      "Epoch 2/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5917 - accuracy: 0.7766 - val_loss: 0.5317 - val_accuracy: 0.7955\n",
      "Epoch 3/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5590 - accuracy: 0.7876 - val_loss: 0.5185 - val_accuracy: 0.7955\n",
      "Epoch 4/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5288 - accuracy: 0.7923 - val_loss: 0.5100 - val_accuracy: 0.7955\n",
      "Epoch 5/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5241 - accuracy: 0.7947 - val_loss: 0.5044 - val_accuracy: 0.7955\n",
      "Epoch 6/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5164 - accuracy: 0.7957 - val_loss: 0.4993 - val_accuracy: 0.7955\n",
      "Epoch 7/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5108 - accuracy: 0.7966 - val_loss: 0.4952 - val_accuracy: 0.7955\n",
      "Epoch 8/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5062 - accuracy: 0.7966 - val_loss: 0.4918 - val_accuracy: 0.7955\n",
      "Epoch 9/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4956 - accuracy: 0.7966 - val_loss: 0.4891 - val_accuracy: 0.7955\n",
      "Epoch 10/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4960 - accuracy: 0.7962 - val_loss: 0.4864 - val_accuracy: 0.7955\n",
      "Epoch 11/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4943 - accuracy: 0.7964 - val_loss: 0.4839 - val_accuracy: 0.7955\n",
      "Epoch 12/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4898 - accuracy: 0.7964 - val_loss: 0.4814 - val_accuracy: 0.7955\n",
      "Epoch 13/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4878 - accuracy: 0.7966 - val_loss: 0.4792 - val_accuracy: 0.7955\n",
      "Epoch 14/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4874 - accuracy: 0.7964 - val_loss: 0.4768 - val_accuracy: 0.7955\n",
      "Epoch 15/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4857 - accuracy: 0.7970 - val_loss: 0.4745 - val_accuracy: 0.7955\n",
      "Epoch 16/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4803 - accuracy: 0.7974 - val_loss: 0.4727 - val_accuracy: 0.7955\n",
      "Epoch 17/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4806 - accuracy: 0.7966 - val_loss: 0.4705 - val_accuracy: 0.7955\n",
      "Epoch 18/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4767 - accuracy: 0.7972 - val_loss: 0.4684 - val_accuracy: 0.7955\n",
      "Epoch 19/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4767 - accuracy: 0.7974 - val_loss: 0.4667 - val_accuracy: 0.7955\n",
      "Epoch 20/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4766 - accuracy: 0.7981 - val_loss: 0.4645 - val_accuracy: 0.7959\n",
      "Epoch 21/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4721 - accuracy: 0.7987 - val_loss: 0.4628 - val_accuracy: 0.7959\n",
      "Epoch 22/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4718 - accuracy: 0.7988 - val_loss: 0.4609 - val_accuracy: 0.7959\n",
      "Epoch 23/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4678 - accuracy: 0.7981 - val_loss: 0.4588 - val_accuracy: 0.7963\n",
      "Epoch 24/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4695 - accuracy: 0.7992 - val_loss: 0.4576 - val_accuracy: 0.7970\n",
      "Epoch 25/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4673 - accuracy: 0.7974 - val_loss: 0.4559 - val_accuracy: 0.7974\n",
      "Epoch 26/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4688 - accuracy: 0.8001 - val_loss: 0.4545 - val_accuracy: 0.7986\n",
      "Epoch 27/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4646 - accuracy: 0.7983 - val_loss: 0.4533 - val_accuracy: 0.7986\n",
      "Epoch 28/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4659 - accuracy: 0.7994 - val_loss: 0.4516 - val_accuracy: 0.7986\n",
      "Epoch 29/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4654 - accuracy: 0.7964 - val_loss: 0.4506 - val_accuracy: 0.7986\n",
      "Epoch 30/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4634 - accuracy: 0.7996 - val_loss: 0.4493 - val_accuracy: 0.7986\n",
      "Epoch 31/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4599 - accuracy: 0.8011 - val_loss: 0.4484 - val_accuracy: 0.7989\n",
      "Epoch 32/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4612 - accuracy: 0.8009 - val_loss: 0.4475 - val_accuracy: 0.7989\n",
      "Epoch 33/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4621 - accuracy: 0.8009 - val_loss: 0.4469 - val_accuracy: 0.7989\n",
      "Epoch 34/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4615 - accuracy: 0.8018 - val_loss: 0.4459 - val_accuracy: 0.7993\n",
      "Epoch 35/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4561 - accuracy: 0.7998 - val_loss: 0.4452 - val_accuracy: 0.7993\n",
      "Epoch 36/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4594 - accuracy: 0.8029 - val_loss: 0.4443 - val_accuracy: 0.7993\n",
      "Epoch 37/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4590 - accuracy: 0.8020 - val_loss: 0.4435 - val_accuracy: 0.7993\n",
      "Epoch 38/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4587 - accuracy: 0.8022 - val_loss: 0.4426 - val_accuracy: 0.7993\n",
      "Epoch 39/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4563 - accuracy: 0.8015 - val_loss: 0.4411 - val_accuracy: 0.8001\n",
      "Epoch 40/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4550 - accuracy: 0.8001 - val_loss: 0.4405 - val_accuracy: 0.8001\n",
      "Epoch 41/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4523 - accuracy: 0.8026 - val_loss: 0.4395 - val_accuracy: 0.8001\n",
      "Epoch 42/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4510 - accuracy: 0.8029 - val_loss: 0.4384 - val_accuracy: 0.8008\n",
      "Epoch 43/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4520 - accuracy: 0.8035 - val_loss: 0.4370 - val_accuracy: 0.8012\n",
      "Epoch 44/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4494 - accuracy: 0.8011 - val_loss: 0.4361 - val_accuracy: 0.8008\n",
      "Epoch 45/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4500 - accuracy: 0.8007 - val_loss: 0.4355 - val_accuracy: 0.8008\n",
      "Epoch 46/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4530 - accuracy: 0.8028 - val_loss: 0.4353 - val_accuracy: 0.8008\n",
      "Epoch 47/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4448 - accuracy: 0.8054 - val_loss: 0.4333 - val_accuracy: 0.8008\n",
      "Epoch 48/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4476 - accuracy: 0.8033 - val_loss: 0.4329 - val_accuracy: 0.8008\n",
      "Epoch 49/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4514 - accuracy: 0.8033 - val_loss: 0.4323 - val_accuracy: 0.8008\n",
      "Epoch 50/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4447 - accuracy: 0.8018 - val_loss: 0.4306 - val_accuracy: 0.8008\n",
      "Epoch 51/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4424 - accuracy: 0.8057 - val_loss: 0.4291 - val_accuracy: 0.8005\n",
      "Epoch 52/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4400 - accuracy: 0.8078 - val_loss: 0.4272 - val_accuracy: 0.8008\n",
      "Epoch 53/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4436 - accuracy: 0.8044 - val_loss: 0.4261 - val_accuracy: 0.8012\n",
      "Epoch 54/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4437 - accuracy: 0.8046 - val_loss: 0.4253 - val_accuracy: 0.8016\n",
      "Epoch 55/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4414 - accuracy: 0.8067 - val_loss: 0.4238 - val_accuracy: 0.8016\n",
      "Epoch 56/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4347 - accuracy: 0.8089 - val_loss: 0.4224 - val_accuracy: 0.8020\n",
      "Epoch 57/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4412 - accuracy: 0.8065 - val_loss: 0.4220 - val_accuracy: 0.8023\n",
      "Epoch 58/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4415 - accuracy: 0.8046 - val_loss: 0.4211 - val_accuracy: 0.8023\n",
      "Epoch 59/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4384 - accuracy: 0.8043 - val_loss: 0.4198 - val_accuracy: 0.8023\n",
      "Epoch 60/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4359 - accuracy: 0.8071 - val_loss: 0.4189 - val_accuracy: 0.8027\n",
      "Epoch 61/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4315 - accuracy: 0.8095 - val_loss: 0.4175 - val_accuracy: 0.8035\n",
      "Epoch 62/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4354 - accuracy: 0.8104 - val_loss: 0.4160 - val_accuracy: 0.8050\n",
      "Epoch 63/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4314 - accuracy: 0.8125 - val_loss: 0.4142 - val_accuracy: 0.8073\n",
      "Epoch 64/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4283 - accuracy: 0.8138 - val_loss: 0.4131 - val_accuracy: 0.8080\n",
      "Epoch 65/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4283 - accuracy: 0.8153 - val_loss: 0.4120 - val_accuracy: 0.8092\n",
      "Epoch 66/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4250 - accuracy: 0.8141 - val_loss: 0.4108 - val_accuracy: 0.8107\n",
      "Epoch 67/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4287 - accuracy: 0.8085 - val_loss: 0.4109 - val_accuracy: 0.8103\n",
      "Epoch 68/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4263 - accuracy: 0.8169 - val_loss: 0.4089 - val_accuracy: 0.8141\n",
      "Epoch 69/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4253 - accuracy: 0.8121 - val_loss: 0.4086 - val_accuracy: 0.8129\n",
      "Epoch 70/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4262 - accuracy: 0.8147 - val_loss: 0.4082 - val_accuracy: 0.8137\n",
      "Epoch 71/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4221 - accuracy: 0.8136 - val_loss: 0.4074 - val_accuracy: 0.8137\n",
      "Epoch 72/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4234 - accuracy: 0.8130 - val_loss: 0.4076 - val_accuracy: 0.8137\n",
      "Epoch 73/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4214 - accuracy: 0.8138 - val_loss: 0.4058 - val_accuracy: 0.8141\n",
      "Epoch 74/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4188 - accuracy: 0.8197 - val_loss: 0.4033 - val_accuracy: 0.8164\n",
      "Epoch 75/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4253 - accuracy: 0.8162 - val_loss: 0.4037 - val_accuracy: 0.8152\n",
      "Epoch 76/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4230 - accuracy: 0.8186 - val_loss: 0.4028 - val_accuracy: 0.8152\n",
      "Epoch 77/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4213 - accuracy: 0.8171 - val_loss: 0.4022 - val_accuracy: 0.8171\n",
      "Epoch 78/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4204 - accuracy: 0.8210 - val_loss: 0.4018 - val_accuracy: 0.8167\n",
      "Epoch 79/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4191 - accuracy: 0.8186 - val_loss: 0.4001 - val_accuracy: 0.8190\n",
      "Epoch 80/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4196 - accuracy: 0.8164 - val_loss: 0.4001 - val_accuracy: 0.8186\n",
      "Epoch 81/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4179 - accuracy: 0.8136 - val_loss: 0.3994 - val_accuracy: 0.8190\n",
      "Epoch 82/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4203 - accuracy: 0.8177 - val_loss: 0.3992 - val_accuracy: 0.8190\n",
      "Epoch 83/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4225 - accuracy: 0.8149 - val_loss: 0.3988 - val_accuracy: 0.8201\n",
      "Epoch 84/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4181 - accuracy: 0.8184 - val_loss: 0.3990 - val_accuracy: 0.8183\n",
      "Epoch 85/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4160 - accuracy: 0.8175 - val_loss: 0.3981 - val_accuracy: 0.8205\n",
      "Epoch 86/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4153 - accuracy: 0.8197 - val_loss: 0.3974 - val_accuracy: 0.8209\n",
      "Epoch 87/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4212 - accuracy: 0.8138 - val_loss: 0.3974 - val_accuracy: 0.8186\n",
      "Epoch 88/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4143 - accuracy: 0.8182 - val_loss: 0.3968 - val_accuracy: 0.8213\n",
      "Epoch 89/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4172 - accuracy: 0.8203 - val_loss: 0.3968 - val_accuracy: 0.8217\n",
      "Epoch 90/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4154 - accuracy: 0.8156 - val_loss: 0.3967 - val_accuracy: 0.8217\n",
      "Epoch 91/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4142 - accuracy: 0.8188 - val_loss: 0.3953 - val_accuracy: 0.8232\n",
      "Epoch 92/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4149 - accuracy: 0.8177 - val_loss: 0.3955 - val_accuracy: 0.8224\n",
      "Epoch 93/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.4145 - accuracy: 0.8155 - val_loss: 0.3959 - val_accuracy: 0.8209\n",
      "Epoch 94/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.4165 - accuracy: 0.8160 - val_loss: 0.3955 - val_accuracy: 0.8209\n",
      "Epoch 95/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4181 - accuracy: 0.8153 - val_loss: 0.3958 - val_accuracy: 0.8209\n",
      "Epoch 96/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4147 - accuracy: 0.8173 - val_loss: 0.3953 - val_accuracy: 0.8213\n",
      "Epoch 97/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4112 - accuracy: 0.8229 - val_loss: 0.3936 - val_accuracy: 0.8270\n",
      "Epoch 98/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4162 - accuracy: 0.8169 - val_loss: 0.3945 - val_accuracy: 0.8217\n",
      "Epoch 99/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4126 - accuracy: 0.8181 - val_loss: 0.3943 - val_accuracy: 0.8220\n",
      "Epoch 100/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4163 - accuracy: 0.8186 - val_loss: 0.3940 - val_accuracy: 0.8217\n"
     ]
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train, y_train,validation_split=0.33, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy dropped to .8217 from .841"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
